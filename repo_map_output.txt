
POC/test_repo_map_standalone.py:
⋮
│def should_ignore(path):
⋮
│def main():
⋮

debug_tree_sitter.py:
⋮
│def explore_tree_sitter():
│    print("Tree-sitter debug exploration")
│
⋮
│    try:
│        # Get Python language and parser
│        python_lang = get_language("python")
⋮
│        def visit_node(node, depth=0):
⋮

reference/base_coder.py:
⋮
│class UnknownEditFormat(ValueError):
│    def __init__(self, edit_format, valid_formats):
│        self.edit_format = edit_format
│        self.valid_formats = valid_formats
│        super().__init__(
│            f"Unknown edit format {edit_format}. Valid formats are: {', '.join(valid_formats)}"
⋮
│class MissingAPIKeyError(ValueError):
⋮
│class FinishReasonLength(Exception):
⋮
│def wrap_fence(name):
⋮
│all_fences = [
│    ("`" * 3, "`" * 3),
│    ("`" * 4, "`" * 4),  # LLMs ignore and revert to triple-backtick, causing #2879
│    wrap_fence("source"),
│    wrap_fence("code"),
│    wrap_fence("pre"),
│    wrap_fence("codeblock"),
│    wrap_fence("sourcecode"),
⋮
│class Coder:
│    abs_fnames = None
⋮
│    @classmethod
│    def create(
│        self,
│        main_model=None,
│        edit_format=None,
│        io=None,
│        from_coder=None,
│        summarize_from_coder=True,
│        **kwargs,
⋮
│    def clone(self, **kwargs):
⋮
│    def get_announcements(self):
⋮
│    def __init__(
│        self,
│        main_model,
│        io,
│        repo=None,
│        fnames=None,
│        read_only_fnames=None,
│        show_diffs=False,
│        auto_commits=True,
│        dirty_commits=True,
⋮
│    def setup_lint_cmds(self, lint_cmds):
⋮
│    def show_announcements(self):
⋮
│    def add_rel_fname(self, rel_fname):
⋮
│    def drop_rel_fname(self, fname):
⋮
│    def abs_root_path(self, path):
⋮
│    def show_pretty(self):
⋮
│    def get_abs_fnames_content(self):
⋮
│    def choose_fence(self):
⋮
│    def get_files_content(self, fnames=None):
⋮
│    def get_read_only_files_content(self):
⋮
│    def get_cur_message_text(self):
⋮
│    def get_ident_mentions(self, text):
⋮
│    def get_ident_filename_matches(self, idents):
⋮
│    def get_repo_map(self, force_refresh=False):
⋮
│    def get_repo_messages(self):
⋮
│    def get_readonly_files_messages(self):
⋮
│    def get_chat_files_messages(self):
⋮
│    def get_images_message(self, fnames):
⋮
│    def run_stream(self, user_message):
⋮
│    def init_before_message(self):
⋮
│    def run(self, with_message=None, preproc=True):
⋮
│    def copy_context(self):
⋮
│    def get_input(self):
⋮
│    def preproc_user_input(self, inp):
⋮
│    def run_one(self, user_message, preproc):
⋮
│    def check_and_open_urls(self, exc, friendly_msg=None):
⋮
│    def check_for_urls(self, inp: str) -> List[str]:
⋮
│    def keyboard_interrupt(self):
⋮
│    def summarize_start(self):
⋮
│    def summarize_worker(self):
⋮
│    def summarize_end(self):
⋮
│    def move_back_cur_messages(self, message):
⋮
│    def get_user_language(self):
⋮
│    def get_platform_info(self):
⋮
│    def fmt_system_prompt(self, prompt):
⋮
│    def format_chat_chunks(self):
⋮
│    def format_messages(self):
⋮
│    def warm_cache(self, chunks):
│        if not self.add_cache_headers:
⋮
│        def warm_cache_worker():
⋮
│    def check_tokens(self, messages):
⋮
│    def send_message(self, inp):
⋮
│    def reply_completed(self):
⋮
│    def show_exhausted_error(self):
⋮
│    def lint_edited(self, fnames):
⋮
│    def __del__(self):
⋮
│    def add_assistant_reply_to_cur_messages(self):
⋮
│    def get_file_mentions(self, content, ignore_current=False):
⋮
│    def check_for_file_mentions(self, content):
⋮
│    def send(self, messages, model=None, functions=None):
⋮
│    def show_send_output(self, completion):
⋮
│    def show_send_output_stream(self, completion):
⋮
│    def live_incremental_response(self, final):
⋮
│    def render_incremental_response(self, final):
⋮
│    def remove_reasoning_content(self):
⋮
│    def calculate_and_show_tokens_and_cost(self, messages, completion=None):
│        prompt_tokens = 0
⋮
│        def format_cost(value):
⋮
│    def show_usage_report(self):
⋮
│    def get_multi_response_content_in_progress(self, final=False):
⋮
│    def get_rel_fname(self, fname):
⋮
│    def get_inchat_relative_files(self):
⋮
│    def is_file_safe(self, fname):
⋮
│    def get_all_relative_files(self):
⋮
│    def get_all_abs_files(self):
⋮
│    def get_addable_relative_files(self):
⋮
│    def check_for_dirty_commit(self, path):
⋮
│    def allowed_to_edit(self, path):
⋮
│    def check_added_files(self):
⋮
│    def prepare_to_edit(self, edits):
⋮
│    def apply_updates(self):
⋮
│    def parse_partial_args(self):
⋮
│    def get_context_from_history(self, history):
⋮
│    def auto_commit(self, edited, context=None):
⋮
│    def show_auto_commit_outcome(self, res):
⋮
│    def show_undo_hint(self):
⋮
│    def dirty_commit(self):
⋮
│    def get_edits(self, mode="update"):
⋮
│    def apply_edits(self, edits):
⋮
│    def apply_edits_dry_run(self, edits):
⋮
│    def run_shell_commands(self):
⋮
│    def handle_shell_commands(self, commands_str, group):
⋮

reference/models.py:
⋮
│RETRY_TIMEOUT = 60
│
│request_timeout = 600
│
│DEFAULT_MODEL_NAME = "gpt-4o"
│ANTHROPIC_BETA_HEADER = "prompt-caching-2024-07-31,pdfs-2024-09-25"
│
│OPENAI_MODELS = """
│o1
│o1-preview
│o1-mini
│o3-mini
│gpt-4
│gpt-4o
│gpt-4o-2024-05-13
│gpt-4-turbo-preview
│gpt-4-0314
⋮
│OPENAI_MODELS = [ln.strip() for ln in OPENAI_MODELS.splitlines() if ln.strip()]
│
│ANTHROPIC_MODELS = """
│claude-2
│claude-2.1
│claude-3-haiku-20240307
│claude-3-5-haiku-20241022
│claude-3-opus-20240229
│claude-3-sonnet-20240229
│claude-3-5-sonnet-20240620
│claude-3-5-sonnet-20241022
⋮
│ANTHROPIC_MODELS = [ln.strip() for ln in ANTHROPIC_MODELS.splitlines() if ln.strip()]
│
⋮
│MODEL_ALIASES = {
│    # Claude models
│    "sonnet": "anthropic/claude-3-7-sonnet-20250219",
│    "haiku": "claude-3-5-haiku-20241022",
│    "opus": "claude-3-opus-20240229",
│    # GPT models
│    "4": "gpt-4-0613",
│    "4o": "gpt-4o",
│    "4-turbo": "gpt-4-1106-preview",
│    "35turbo": "gpt-3.5-turbo",
⋮
│@dataclass
│class ModelSettings:
⋮
│MODEL_SETTINGS = []
⋮
│class ModelInfoManager:
│    MODEL_INFO_URL = (
│        "https://raw.githubusercontent.com/BerriAI/litellm/main/"
│        "model_prices_and_context_window.json"
⋮
│    def __init__(self):
⋮
│    def set_verify_ssl(self, verify_ssl):
⋮
│    def _load_cache(self):
⋮
│    def _update_cache(self):
⋮
│    def get_model_from_cached_json_db(self, model):
⋮
│    def get_model_info(self, model):
⋮
│model_info_manager = ModelInfoManager()
│
⋮
│class Model(ModelSettings):
│    def __init__(
│        self, model, weak_model=None, editor_model=None, editor_edit_format=None, verbose=False
⋮
│    def get_model_info(self, model):
⋮
│    def _copy_fields(self, source):
⋮
│    def configure_model_settings(self, model):
⋮
│    def apply_generic_model_settings(self, model):
⋮
│    def __str__(self):
⋮
│    def get_weak_model(self, provided_weak_model_name):
⋮
│    def commit_message_models(self):
⋮
│    def get_editor_model(self, provided_editor_model_name, editor_edit_format):
⋮
│    def tokenizer(self, text):
⋮
│    def token_count(self, messages):
⋮
│    def token_count_for_image(self, fname):
⋮
│    def get_image_size(self, fname):
⋮
│    def fast_validate_environment(self):
⋮
│    def validate_environment(self):
⋮
│    def get_repo_map_tokens(self):
⋮
│    def set_reasoning_effort(self, effort):
⋮
│    def parse_token_value(self, value):
⋮
│    def set_thinking_tokens(self, value):
⋮
│    def get_raw_thinking_tokens(self):
⋮
│    def get_thinking_tokens(self):
⋮
│    def get_reasoning_effort(self):
⋮
│    def is_deepseek_r1(self):
⋮
│    def is_ollama(self):
⋮
│    def send_completion(self, messages, functions, stream, temperature=None):
⋮
│    def simple_send_with_retries(self, messages):
⋮
│def register_models(model_settings_fnames):
⋮
│def register_litellm_models(model_fnames):
⋮
│def validate_variables(vars):
⋮
│def sanity_check_models(io, main_model):
⋮
│def sanity_check_model(io, model):
⋮
│def check_for_dependencies(io, model_name):
⋮
│def fuzzy_match_models(name):
⋮
│def print_matching_models(io, search):
⋮
│def get_model_settings_as_yaml():
⋮
│def main():
⋮

reference/repomap.py:
⋮
│Tag = namedtuple("Tag", "rel_fname fname line name kind".split())
│
⋮
│SQLITE_ERRORS = (sqlite3.OperationalError, sqlite3.DatabaseError, OSError)
│
⋮
│CACHE_VERSION = 3
⋮
│class RepoMap:
│    TAGS_CACHE_DIR = f".aider.tags.cache.v{CACHE_VERSION}"
│
⋮
│    def __init__(
│        self,
│        map_tokens=1024,
│        root=None,
│        main_model=None,
│        io=None,
│        repo_content_prefix=None,
│        verbose=False,
│        max_context_window=None,
│        map_mul_no_files=8,
⋮
│    def token_count(self, text):
⋮
│    def get_repo_map(
│        self,
│        chat_files,
│        other_files,
│        mentioned_fnames=None,
│        mentioned_idents=None,
│        force_refresh=False,
⋮
│    def get_rel_fname(self, fname):
⋮
│    def tags_cache_error(self, original_error=None):
⋮
│    def load_tags_cache(self):
⋮
│    def save_tags_cache(self):
⋮
│    def get_mtime(self, fname):
⋮
│    def get_tags(self, fname, rel_fname):
⋮
│    def get_tags_raw(self, fname, rel_fname):
⋮
│    def get_ranked_tags(
│        self, chat_fnames, other_fnames, mentioned_fnames, mentioned_idents, progress=None
⋮
│    def get_ranked_tags_map(
│        self,
│        chat_fnames,
│        other_fnames=None,
│        max_map_tokens=None,
│        mentioned_fnames=None,
│        mentioned_idents=None,
│        force_refresh=False,
⋮
│    def get_ranked_tags_map_uncached(
│        self,
│        chat_fnames,
│        other_fnames=None,
│        max_map_tokens=None,
│        mentioned_fnames=None,
│        mentioned_idents=None,
⋮
│    def render_tree(self, abs_fname, rel_fname, lois):
⋮
│    def to_tree(self, tags, chat_rel_fnames):
⋮
│def find_src_files(directory):
⋮
│def get_random_color():
⋮
│def get_scm_fname(lang):
⋮
│def get_supported_languages_md():
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/__init__.py

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/cli.py:
⋮
│def prompt_with_choices(text, choices):
⋮
│def prompt_yes_no(question: str) -> bool:
⋮
│def gather_user_info() -> UserInfo:
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/config.py:
⋮
│class UserInfo(BaseModel):
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/main.py:
⋮
│def format_training_plan(training_plan):
⋮
│def main():
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/openai_utils.py:
⋮
│root_dir = Path(__file__).resolve().parent.parent
│
⋮
│dotenv_path = root_dir / '.env'
⋮
│client = OpenAI(
│    api_key=os.getenv("API_KEY"),
│    base_url=os.getenv("BASE_URL"),
⋮
│model_name = os.getenv("MODEL_NAME")
│
│def get_training_plan(prompt: str) -> TrainingPlan:
⋮
│def get_practice_task(prompt: str) -> str:
⋮
│def send_openai_request(prompt: str) -> str:
⋮
│def parse_openai_response(response: str) -> dict:
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/prompt_generator.py:
⋮
│def generate_task_prompt(milestone: dict, user_info: UserInfo, training_plan: TrainingPlan) -> str:
⋮
│def generate_prompt(user_info: UserInfo) -> str:
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/schemas.py:
⋮
│class Milestone(BaseModel):
⋮
│class TrainingPlan(BaseModel):
⋮

repo_cache/github/codingthefuturewithai/python-trainer-99db7102/python_trainer/utils/file_utils.py:
⋮
│def create_output_directory() -> Path:
⋮
│def save_training_plan(training_plan: str, filename: str) -> Path:
⋮
│def save_practice_task(task: str, milestone_number: int) -> Path:
⋮

src/code_understanding/__init__.py:
⋮
│__version__ = "0.1.0"
│
⋮
│config = load_config()
⋮

src/code_understanding/config.py:
⋮
│@dataclass
│class IndexerConfig:
⋮
│@dataclass
│class TreeSitterConfig:
│    queries_path: str = "./src/code_understanding/treesitter/queries"
⋮
│    def __post_init__(self):
⋮
│@dataclass
│class GitHubConfig:
⋮
│@dataclass
│class RepositoryConfig:
│    cache_dir: str = "./repo_cache"
⋮
│    def __post_init__(self):
⋮
│@dataclass
│class ContextConfig:
⋮
│@dataclass
│class ParserConfig:
│    enabled_languages: List[str] = None
│
│    def __post_init__(self):
⋮
│@dataclass
│class ServerConfig:
│    name: str = "Code Understanding Server"
⋮
│    def __post_init__(self):
⋮
│def load_config(config_path: str = "config.yaml") -> ServerConfig:
⋮

src/code_understanding/context/__init__.py:
⋮
│__all__ = ["ContextGenerator"]

src/code_understanding/context/generator.py:
⋮
│logger = logging.getLogger(__name__)
│
⋮
│class ContextGenerator:
│    def __init__(self, config: ContextConfig):
│        # Get complete config to pass to create_parsers
│        try:
│            full_config = load_config()
│
│            # Use the factory to create parsers
│            self.parsers_list = create_parsers(full_config)
│            logger.info(f"Initialized {len(self.parsers_list)} parsers")
│        except Exception as e:
│            logger.error(f"Error initializing parsers: {e}")
⋮
│    async def generate_context(self, repo: Repository) -> Dict[str, Any]:
⋮
│    async def _analyze_structure(self, repo: Repository) -> Dict[str, Any]:
⋮
│    async def _generate_summary(self, repo: Repository) -> Dict[str, Any]:
⋮

src/code_understanding/indexer/__init__.py

src/code_understanding/indexer/embedder.py:
⋮
│class CodeEmbedder:
│    """Handles code embedding using language-aware splitting."""
│
│    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
⋮
│    async def embed_file(self, file_path: Path, content: str) -> List[float]:
⋮

src/code_understanding/indexer/vector_store.py:
⋮
│class VectorStore:
│    """Manages vector storage and retrieval using ChromaDB."""
│
│    def __init__(self, db_path: Path):
⋮
│    async def store_embeddings(
│        self, file_path: str, embeddings: List[float], metadata: Dict[str, Any]
⋮
│    async def search(
│        self, query_embedding: List[float], limit: int = 5
⋮

src/code_understanding/logging_config.py:
⋮
│def get_default_log_dir() -> Path:
⋮
│def setup_logging(server_config: Optional[ServerConfig] = None) -> None:
⋮
│logger = logging.getLogger("code_understanding")

src/code_understanding/mcp/__init__.py:
⋮
│__version__ = "0.1.0"
│__all__ = ["server", "create_mcp_server"]
│
│def main(transport: str = "stdio"):
⋮

src/code_understanding/mcp/server/__init__.py:
⋮
│__all__ = ["server", "create_mcp_server"]

src/code_understanding/mcp/server/app.py:
⋮
│logger = logging.getLogger("code_understanding.mcp")
│
⋮
│def create_mcp_server(config: Optional[ServerConfig] = None) -> FastMCP:
⋮
│def register_tools(
│    mcp_server: FastMCP,
│    repo_manager: RepositoryManager,
│    context_generator: ContextGenerator,
│    search_engine: SearchEngine,
│) -> None:
│    """Register all MCP tools with the server."""
│
│    @mcp_server.tool(
│        name="get_context",
│        description="Generate and return structured context about a repository",
│    )
│    async def get_context(repo_path: str) -> dict:
⋮
│    @mcp_server.tool(
│        name="get_resource", description="Retrieve specific files or directory listings"
│    )
│    async def get_resource(repo_path: str, resource_path: str) -> dict:
⋮
│    @mcp_server.tool(
│        name="search_codebase",
│        description="Search the codebase for relevant code snippets (temporary implementation)",
│    )
│    async def search_codebase(repo_path: str, query: str) -> dict:
⋮
│    @mcp_server.tool(
│        name="refresh_repo",
│        description="Update a remote repository with latest changes",
│    )
│    async def refresh_repo(repo_path: str) -> dict:
⋮
│    @mcp_server.tool(name="clone_repo", description="Clone a new remote repository")
│    async def clone_repo(url: str, branch: Optional[str] = None) -> dict:
⋮
│server = create_mcp_server()
│
⋮
│@click.command()
⋮
│def main(port: int, transport: str) -> int:
⋮

src/code_understanding/parsers/__init__.py:
⋮
│def create_parsers(config: ServerConfig) -> List[BaseParser]:
⋮

src/code_understanding/parsers/base.py:
⋮
│class BaseParser(ABC):
│    @abstractmethod
│    def can_parse(self, file_path: str) -> bool:
│        """Check if this parser can handle the given file."""
⋮
│    @abstractmethod
│    async def parse_file(self, content: str, file_path: str) -> Dict[str, Any]:
⋮

src/code_understanding/parsers/treesitter_adapter.py:
⋮
│class TreeSitterParser(BaseParser):
│    """Adapter to use Tree-sitter CodeParser with the BaseParser interface."""
│
│    def __init__(self, queries_path: Path):
⋮
│    def can_parse(self, file_path: str) -> bool:
⋮
│    async def parse_file(self, content: str, file_path: str) -> Dict[str, Any]:
⋮

src/code_understanding/repomap/__init__.py

src/code_understanding/repository/__init__.py:
⋮
│__all__ = ["Repository", "RepositoryManager", "RepositoryCache"]

src/code_understanding/repository/cache.py:
⋮
│logger = logging.getLogger(__name__)
│
⋮
│@dataclass
│class RepositoryMetadata:
⋮
│class RepositoryCache:
│    def __init__(
│        self, cache_dir: Path, max_cached_repos: int = 50, cleanup_interval: int = 86400
⋮
│    @contextmanager
│    def _file_lock(self):
⋮
│    def _get_actual_repos(self) -> Set[str]:
⋮
│    def _read_metadata(self) -> Dict[str, RepositoryMetadata]:
⋮
│    def _write_metadata(self, metadata: Dict[str, RepositoryMetadata]):
⋮
│    def _sync_metadata(self) -> Dict[str, RepositoryMetadata]:
⋮
│    async def prepare_for_clone(self, target_path: str) -> bool:
⋮
│    async def add_repo(self, path: str, url: Optional[str] = None):
⋮
│    async def update_access(self, path: str):
⋮
│    async def remove_repo(self, path: str):
⋮
│    async def cleanup_old_repos(self):
⋮

src/code_understanding/repository/manager.py:
⋮
│class Repository:
│    def __init__(
│        self,
│        repo_id: str,
│        root_path: Path,
│        repo_type: str,
│        is_git: bool,
│        url: Optional[str] = None,
│        branch: Optional[str] = None,
│        manager: Optional["RepositoryManager"] = None,
⋮
│    def is_ignored(self, path: Union[str, Path]) -> bool:
⋮
│    async def get_resource(self, resource_path: str) -> Dict[str, Any]:
⋮
│    async def refresh(self) -> Dict[str, Any]:
⋮
│class RepositoryManager:
│    def __init__(self, config: RepositoryConfig):
│        self.config = config
│        self.cache_dir = Path(config.cache_dir)
│        self.cache_dir.mkdir(parents=True, exist_ok=True)
│        self.repositories: Dict[str, Repository] = {}
⋮
│    def _cleanup_if_needed(self):
⋮
│    async def get_repository(self, path: str) -> Repository:
⋮
│    async def clone_repository(
│        self, url: str, branch: Optional[str] = None
⋮
│    async def refresh_repository(self, path: str) -> Dict[str, Any]:
⋮
│    async def cleanup(self):
⋮

src/code_understanding/repository/path_utils.py:
⋮
│def is_git_url(path: str) -> bool:
⋮
│def parse_github_url(url: str) -> Tuple[str, str, Optional[str]]:
⋮
│def get_cache_path(cache_dir: Path, repo_path: str) -> Path:
⋮

src/code_understanding/search/__init__.py:
⋮
│__all__ = ["SearchEngine"]

src/code_understanding/search/engine.py:
⋮
│class SearchEngine:
│    """Handles code search and retrieval functionality.
│
│    This is currently a simple keyword-based implementation, but will be
│    enhanced with vector store capabilities in the future.
⋮
│    def __init__(self):
⋮
│    async def search(self, repo: Repository, query: str) -> Dict[str, Any]:
⋮
│    async def answer_question(self, repo: Repository, question: str) -> Dict[str, str]:
⋮
│    async def _find_relevant_files(
│        self, repo: Repository, query: str
⋮
│    def _extract_keywords(self, text: str) -> List[str]:
⋮
│    def _rank_chunks(self, chunks: List[Document], query: str) -> List[Document]:
│        """Rank chunks by relevance to the query."""
⋮
│        def rank_chunk(chunk: Document) -> int:
⋮
│    def _get_highlights(
│        self, content: str, keywords: List[str]
⋮

src/code_understanding/treesitter/__init__.py

src/code_understanding/treesitter/language_registry.py:
⋮
│class LanguageRegistry:
│    """Manages language detection and Tree-sitter language mappings."""
│
⋮
│    def __init__(self, queries_path: Path):
⋮
│    def detect_language(self, file_path: Path) -> Optional[str]:
⋮
│    def get_language(self, language_id: str):
⋮
│    def get_parser(self, language_id: str):
⋮
│    def get_query_file(self, language: str) -> Optional[Path]:
⋮

src/code_understanding/treesitter/parser.py:
⋮
│logger = logging.getLogger(__name__)
│
⋮
│class Symbol:
│    """Represents a code symbol with location information."""
│
│    def __init__(
│        self,
│        name: str,
│        type: str,
│        start_line: int,
│        start_col: int,
│        end_line: int,
│        end_col: int,
│        parent: Optional["Symbol"] = None,
⋮
│    def to_dict(self) -> Dict[str, Any]:
⋮
│class CodeParser:
│    """Handles code parsing and symbol extraction using Tree-sitter."""
│
│    def __init__(self, queries_path: Path):
⋮
│    def _get_text(self, node: Node, content: str) -> str:
⋮
│    def _find_name_node(self, node: Node) -> Optional[Node]:
⋮
│    async def extract_symbols(
│        self, file_path: Path, content: str
⋮

src/code_understanding/treesitter/queries/__init__.py

src/test_aider_repomap.py:
⋮
│def should_include_file(file_path: str) -> bool:
⋮
│def main():
⋮

tests/test_direct.py:
⋮
│def test_tree_sitter_direct():
⋮

tests/test_repository_cache.py:
⋮
│@pytest.fixture
│def temp_cache_dir(tmp_path):
⋮
│@pytest.fixture
│def cache(temp_cache_dir):
⋮
│def create_test_repo(cache_dir: Path, name: str) -> Path:
⋮
│@pytest.mark.asyncio
│async def test_cache_initialization(temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_metadata_creation_and_sync(cache, temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_prepare_for_clone(cache, temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_update_access(cache, temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_cleanup_old_repos(cache, temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_concurrent_operations(cache, temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_atomic_metadata_writes(cache, temp_cache_dir):
⋮
│@pytest.mark.asyncio
│async def test_remove_repo(cache, temp_cache_dir):
⋮

tests/test_repository_manager.py:
⋮
│@pytest.fixture
│def repo_with_gitignore(tmp_path):
⋮
│def test_gitignore_filtering(repo_with_gitignore):
⋮
│def test_gitignore_dynamic_update(repo_with_gitignore):
⋮
│def test_no_gitignore_file(tmp_path):
⋮

tests/test_treesitter.py:
⋮
│async def test_parser():
⋮

tests/test_treesitter_symbols.py:
⋮
│async def test_symbol_extraction():
⋮
